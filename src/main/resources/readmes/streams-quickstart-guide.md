# Краткое руководство по потокам

### Зависимость
Чтобы использовать потоки Akka, добавьте модуль в свой проект:

```sbtshell
libraryDependencies += "com.typesafe.akka" %% "akka-stream" % "2.5.17"
```

### Первые шаги
Обычно поток начинается с источника, мы также начинаем в Akka Stream. Прежде чем создать его, мы импортируем 
полный набор средств потоковой передачи:

```scala
import akka.stream._
import akka.stream.scaladsl._
```
Если вы хотите выполнить образцы кода во время чтения `руководства по быстрому старту`, вам также понадобятся следующий импорт:

```scala
import akka.{ NotUsed, Done }
import akka.actor.ActorSystem
import akka.util.ByteString
import scala.concurrent._
import scala.concurrent.duration._
import java.nio.file.Paths
```

И объект для хранения вашего кода, например:
```scala
object Main extends App {
  // код здесь
}
```
Теперь мы начнем с довольно простого источника, испускающего целые числа от 1 до 100:

```scala
val source: Source[Int, NotUsed] = Source(1 to 100)
```
_Тип источника параметризуется двумя типами_: **первый - это тип элемента**, который этот источник испускает, а **второй** может 
сигнализировать о том, что запуск источника приводит к некоторому вспомогательному значению, _например, сетевой источник 
может предоставлять информацию о связанном порте или одноранговой сети адрес_. В тех случаях, когда не создается 
вспомогательная информация, используется тип `akka.NotUsed`, и простой класс целых чисел, несомненно, попадает в эту категорию.

Создав этот источник, мы имеем описание того, как испускать первые 100 натуральных чисел, но этот источник еще не 
активирован. Чтобы получить эти номера, мы должны запустить его:

```scala
source.runForeach(i ⇒ println(i))(materializer)
```
Эта строка дополнит источник функцией пользователя - в этом примере мы печатаем номера в консоли и передаем эту 
небольшую настройку потока aктора, который его запускает. Эта активация сигнализируется тем, что «run» является 
частью имени метода; есть и другие методы, которые управляют потоками Akka, и все они следуют этому шаблону.

При запуске `StreamHelloSpec` этого источника вы можете заметить, что он не завершается, потому что `ActorSystem`
никогда не прерывается. К счастью, `runForeach` возвращает `Future[Done]`, которое разрешается, когда поток заканчивается:

```scala
val done: Future[Done] = source.runForeach(i ⇒ println(i))(materializer)

implicit val ec = system.dispatcher
done.onComplete(_ ⇒ system.terminate())
```

Вы можете задаться вопросом, где создается aктор, который управляет потоком, и вы, вероятно, также спрашиваете 
себя, что означает этот материализатор. Чтобы получить это значение, нам сначала нужно создать систему aктора:

```scala
implicit val system = ActorSystem("QuickStart")
implicit val materializer = ActorMaterializer()
```
Существуют и другие способы создания материализатора, например, из `ActorContext` при использовании потоков изнутри 
акторов. `Materializer` - это фабрика для движков потока, то, что делает потоки запускаемыми - вам не нужно 
беспокоиться ни о каких деталях прямо сейчас, кроме того, что вам нужно для вызова любого из методов запуска в источнике. 
Материализатор подбирается неявно, если он опущен из аргументов вызова метода запуска, что мы будем делать далее.

Самое приятное в потоках Akka - это то, что `Source` - это описание того, что вы хотите запустить, и, как проект 
архитектора, его можно использовать повторно, встроенный в более крупный дизайн. Мы можем выбрать преобразование 
источника целых чисел и вместо этого записать его в файл:

```scala
val factorials = source.scan(BigInt(1))((acc, next) ⇒ acc * next)

val result: Future[IOResult] =
  factorials
    .map(num ⇒ ByteString(s"$num\n"))
    .runWith(FileIO.toPath(Paths.get("factorials.txt")))
```

Сначала мы используем оператор сканирования для выполнения вычисления по всему потоку: начиная с номера 1 (`BigInt (1)`) 
мы умножаем каждый из входящих чисел один за другим; операция сканирования выдает начальное значение, а затем каждый 
результат вычисления. Это дает ряд факториальных чисел, которые мы откладываем в качестве источника (`Source`) для последующего 
повторного использования. Важно помнить, что пока ничего не вычисляется, это описание того, что мы хотим вычислить, 
как только мы запускаем поток. Затем мы преобразуем полученную серию чисел в поток объектов `ByteString`, описывающих 
строки в текстовом файле. Затем этот поток запускается путем присоединения файла в качестве получателя данных. В 
терминологии потоков Акка это называется **`Sink`**. `IOResult` - это тип, в котором операции ввода-вывода возвращаются в 
потоках Akka, чтобы рассказать вам, сколько байтов или элементов было потреблено, и был ли поток прекращен нормально 
или с исключением.

#### Пример с использованием браузера
Вот еще один пример, который вы можете редактировать и запускать в браузере:

```scala
import akka.NotUsed
import akka.actor.ActorSystem
import akka.stream.ActorMaterializer
import akka.stream.scaladsl._

object HelloTweets extends App {
  implicit val system       = ActorSystem("reactive-tweets")
  implicit val materializer = ActorMaterializer()

  final case class Author(handle: String)
  final case class Hashtag(name: String)
  final case class Tweet(author: Author, timestamp: Long, body: String) {
    def hashtags: Set[Hashtag] =
      body
        .split(" ")
        .collect {
          case t if t.startsWith("#") ⇒ Hashtag(t.replaceAll("[^#\\w]", ""))
        }
        .toSet
  }

  val akkaTag = Hashtag("#akka")

  val tweets: Source[Tweet, NotUsed] = Source(
    Tweet(Author("rolandkuhn"), System.currentTimeMillis, "#akka rocks!") ::
      Tweet(Author("patriknw"), System.currentTimeMillis, "#akka !") ::
      Tweet(Author("bantonsson"), System.currentTimeMillis, "#akka !") ::
      Tweet(Author("drewhk"), System.currentTimeMillis, "#akka !") ::
      Tweet(Author("ktosopl"), System.currentTimeMillis, "#akka on the rocks!") ::
      Tweet(Author("mmartynas"), System.currentTimeMillis, "wow #akka !") ::
      Tweet(Author("akkateam"), System.currentTimeMillis, "#akka rocks!") ::
      Tweet(Author("bananaman"), System.currentTimeMillis, "#bananas rock!") ::
      Tweet(Author("appleman"), System.currentTimeMillis, "#apples rock!") ::
      Tweet(Author("drama"), System.currentTimeMillis, "we compared #apples to #oranges!") ::
      Nil)

  tweets
    .map(_.hashtags)                // Получить все наборы хэштегов ...
    .reduce(_ ++ _)                 // ... и сводить их к одному набору, удаляя дубликаты во всех твитах
    .mapConcat(identity)            // Сглаживание потока твитов в поток хэштегов
    .map(_.name.toUpperCase)        // Преобразование всех хэштегов в верхний регистр
    .runWith(Sink.foreach(println)) // Прикрепите поток к раковине, который, наконец, распечатает хэштеги
}
```

### Многоразовые части
Одна из красивейших частей потоков Akka - и то, что другие библиотеки потоков не предлагают, заключается в том, что **не 
только источники могут быть повторно использованы**, как чертежи, но и все остальные элементы. Мы можем взять `Sink` для 
записи файлов, добавив шаги обработки, необходимые для получения элементов `ByteString` из входящих строк и пакетов, 
которые также можно использовать для повторного использования. Поскольку язык для записи этих потоков всегда течет 
слева направо, нам нужна начальная точка, которая похожа на источник, но с «открытым» вводом. 
В потоках Akka это называется Потоком (`Flow`):

```scala
def lineSink(filename: String): Sink[String, Future[IOResult]] =
  Flow[String]
    .map(s ⇒ ByteString(s + "\n"))
    .toMat(FileIO.toPath(Paths.get(filename)))(Keep.right)
```

Начиная с потока строк, мы конвертируем каждый в `ByteString`, а затем загружаем в уже известный файловый `Sink`. 
Итоговый чертеж представляет собой `Sink[String, Future [IOResult]]`, что означает, что он принимает строки в качестве 
своего ввода, и при материализации он будет создавать вспомогательную информацию типа `Future[IOResult]` (при операции 
цепочки на `Source` или `Flow` тип вспомогательная информация, называемая «материализованным значением», задается 
самой левой начальной точкой, так как мы хотим сохранить то, что `FileIO.toPath` может предложить сток (`Sink`), мы должны 
сказать `Keep.right`).

Мы можем использовать новый и блестящий `Sink`, который мы только что создали, подключив его к нашему источнику 
факториалов - после небольшой адаптации, чтобы превратить числа в строки:

```scala
factorials.map(_.toString).runWith(lineSink("factorial2.txt"))
```

### Обработка по времени
Прежде чем мы начнем рассматривать более привлекательный пример, мы исследуем потоковый характер того, что могут сделать
 Akka Streams. Исходя из источника факториалов (`factorials`), мы преобразуем поток, сжимая его вместе с другим потоком, 
 представленным Источником (`Source`), который испускает число от 0 до 100: первое число, испускаемое источником факториалов, 
 является факториалом  нуля, второе - факториалом одного , и так далее. Мы объединяем эти два, формируя строки типа `3! = 6`.

```scala
factorials
  .zipWith(Source(0 to 100))((num, idx) ⇒ s"$idx! = $num")
  .throttle(1, 1.second)
  .runForeach(println)
```

Все операции до сих пор были независимыми от времени и могли быть выполнены таким же образом по строгим наборам элементов. 
Следующая строка демонстрирует, что мы на самом деле имеем дело с потоками, которые могут протекать с определенной 
скоростью: мы используем оператор дроссельной заслонки (`throttle`) для замедления потока до 1 элемента в секунду.

Если вы запустите эту программу, вы увидите одну строку, напечатанную в секунду. Один аспект, который не сразу заметен, 
заслуживает упоминания, хотя: если вы попытаетесь установить потоки для создания миллиарда чисел каждый, вы заметите, 
что ваша JVM не падает с `OutOfMemoryError`, хотя вы также заметите, что запуск потоков происходит в фоновом режиме, 
асинхронно (_вот почему в будущем дополнительная информация будет предоставлена ​​как `Future`_). Секрет, который делает эту 
работу, заключается в том, что **потоки Akka неявно реализуют повсеместное управление потоком**, все операторы уважают 
противодавление. Это позволяет оператору дроссельной заслонки сообщать всем своим восходящим источникам данных, что он 
может принимать только элементы с определенной скоростью - когда скорость входящего потока выше, чем одна секунда, 
оператор дроссельной заслонки будет поддерживать обратное давление вверх по течению.

Это все, что есть в потоках Akka, в двух словах, за счет того, что на выбор есть десятки источников и поглотителей и 
многие другие операторы преобразования потока, см. также [индекс оператора](https://doc.akka.io/docs/akka/current/stream/operators/index.html).

## Реактивные твиты 
>(см. файл `ru.reactive_tweets.TwitterStreamQuickstartDocSpec` в папке с тестами)

Типичный пример использования для обработки потока - это поток данных, который мы хотим извлечь или скомпилировать 
некоторые другие данные. В этом примере мы рассмотрим возможность использования потока твитов и извлечения из них 
информации об Акке.

_Мы также рассмотрим проблему, присущую всем неблокирующим потоковым решениям: «Что, если абонент слишком медленный, 
чтобы потреблять живой поток данных?». Традиционно решение часто должно буферизировать элементы, но это может и, как 
правило, вызовет возможные переполнения буфера и нестабильность таких систем._ Вместо этого **потоки Akka зависят от 
внутренних сигналов обратного давления**, которые позволяют управлять тем, что должно произойти в таких сценариях.

Вот модель данных, с которой мы будем работать во всех примерах быстрого запуска:

```scala
final case class Author(handle: String)

final case class Hashtag(name: String)

final case class Tweet(author: Author, timestamp: Long, body: String) {
def hashtags: Set[Hashtag] =
  body
    .split(" ")
    .collect {
      case t if t.startsWith("#") ⇒ Hashtag(t.replaceAll("[^#\\w]", ""))
    }
    .toSet
}

val akkaTag = Hashtag("#akka")
```

>Если вы хотите сначала получить обзор используемого словаря, а не погрузиться с головой в первый пример, вы можете 
взглянуть на разделы [Основные понятия](https://doc.akka.io/docs/akka/current/stream/stream-flows-and-basics.html#core-concepts)
 и [Определение и запуск потоков](https://doc.akka.io/docs/akka/current/stream/stream-flows-and-basics.html#defining-and-running-streams),
  а затем вернуться к этому быстрому старту, чтобы см. все это вместе в простой пример приложения.


### Преобразование и использование простых потоков
Пример приложения, на который мы будем смотреть, - это простой поток новостей Twitter, из которого мы хотим извлечь 
определенную информацию, например, найти все твиттер упоминания пользователей, которые твитят об `#akka`.

Чтобы подготовить нашу среду, создадим `ActorSystem` и `ActorMaterializer`, которые будут отвечать за материализацию и 
управление потоками, которые мы собираемся создать:

```scala
implicit val system = ActorSystem("reactive-tweets")
implicit val materializer = ActorMaterializer()
```

`ActorMaterializer` может при необходимости использовать `ActorMaterializerSettings`, которые могут быть использованы 
для определения свойств материализации, таких как размеры буфера по умолчанию (см. также [Буферы для асинхронных 
операторов](https://doc.akka.io/docs/akka/current/stream/stream-rate.html#async-stream-buffers)), диспетчер, который 
будет использоваться конвейером и т.д. Они могут быть переопределены с помощью атрибутов (`withAttributes`) 
`Flow`, `Source`, `Sink` и `Graph`.

Предположим, у нас есть поток твитов, которые легко доступны. В Акке это выражается как `Sourcs[Out, M]`:

```scala
val tweets: Source[Tweet, NotUsed]
```

Потоки всегда начинают течь из `Source[Out, M1]`, а затем могут продолжаться через элементы `Flow[In, Out, M2]` или 
более продвинутые операторы, чтобы, наконец, потребляться `Sink[In, M3]` _(игнорируйте параметры типа `M1`, `M2` и `M3`, они 
не имеют отношения к типам элементов, созданных/потребляемых (`produced/consumed`) этими классами - они являются 
«материализованными типами», о которых мы поговорим ниже)._

Операции должны быть знакомы всем, кто использовал библиотеку `Scala Collections`, однако они работают с потоками, а не с 
коллекциями данных (что является очень важным отличием, поскольку некоторые операции имеют смысл только при потоковой 
передаче и наоборот):
```scala
val authors: Source[Author, NotUsed] =
  tweets
    .filter(_.hashtags.contains(akkaTag))
    .map(_.author)
```

Наконец, чтобы материализовать и запустить вычисление потока, нам нужно прикрепить `Flow` к `Sink`, это позволит запустить поток.
 Самый простой способ сделать это - вызвать `runWith(sink)` в источнике. Для удобства ряд общих приемников предопределены 
 и собраны как методы на объекте компаньона `Sink`. Теперь давайте напечатаем каждого автора:
 
```scala
authors.runWith(Sink.foreach(println))
```

или используя сокращенную версию (которые определены только для самых популярных Sinks, таких как `Sink.fold` и `Sink.foreach`):

```scala
authors.runForeach(println)
```
Материализация и управление потоком всегда требует, чтобы `Materializer` находился в неявной области (или передавался 
явно, например: `.run(materializer)`).

Полный фрагмент выглядит следующим образом:

```scala
implicit val system = ActorSystem("reactive-tweets")
implicit val materializer = ActorMaterializer()

val authors: Source[Author, NotUsed] =
  tweets
    .filter(_.hashtags.contains(akkaTag))
    .map(_.author)

authors.runWith(Sink.foreach(println))
```

### Сглаживание последовательностей в потоках
В предыдущем разделе мы работали над отношениями `1:1` элементов, которые являются наиболее распространенным случаем, 
но иногда нам может понадобиться сопоставить один элемент на несколько элементов и получить «сплющенный» поток, подобно 
тому, как `flatMap` работает на Scala Коллекции. Чтобы получить сплющенный поток хэштегов из нашего потока твитов, мы 
можем использовать оператор `mapConcat`:

```scala
val hashtags: Source[Hashtag, NotUsed] = tweets.mapConcat(_.hashtags.toList)
```

>Название `flatMap` сознательно избегалось из-за его близости к `for-comprehensions` и монадической композиции. Это 
проблематично по двум причинам: **во-первых**, сглаживание путем конкатенации часто нежелательно в ограниченной обработке 
потока из-за риска взаимоблокировки (при условии, что объединение является предпочтительной стратегией), а **во-вторых**, 
законы монады не будут соблюдаться для нашей реализации `flatMap` (из-за к проблемам жизнедеятельности).
Обратите внимание, что `mapConcat` требует, чтобы предоставленная функция возвращала `iterable` 
(`f: Out => immutable.Iterable [T]`, тогда как `flatMap` должен был работать на потоках до конца.


### Трансляция потока (Broadcasting a stream)
Теперь предположим, что мы хотим сохранить все хэштеги, а также все имена авторов из этого одного потока в прямом эфире. 
Например, мы хотели бы написать все рукописи автора в один файл и все хэштеги в другой файл на диске. Это означает, что 
мы должны разделить поток источника на два потока, которые будут обрабатывать запись в эти разные файлы.

Элементы, которые могут быть использованы для формирования таких «вентиляторных» (или «вставных») структур, называются 
«перекрестками» в потоках Акка. Один из них, который мы будем использовать в этом примере, называется `Broadcast`, и он 
испускает элементы из своего входного порта во все его выходные порты.

Потоки Akka преднамеренно разделяют линейные потоковые структуры (`Flows`) от нелинейных ветвящихся (`Graphs`), чтобы 
предложить наиболее удобный API для обоих этих случаев. Графы (`Graphs`) могут выражать произвольно сложные потоковые 
настройки за счет того, что они не читаются так же хорошо, как преобразования коллекции.

Графы конструируются с использованием `GraphDSL` следующим образом:

```scala
val writeAuthors: Sink[Author, NotUsed] = ???
val writeHashtags: Sink[Hashtag, NotUsed] = ???
val g = RunnableGraph.fromGraph(GraphDSL.create() { implicit b =>
  import GraphDSL.Implicits._

  val bcast = b.add(Broadcast[Tweet](2))
  tweets ~> bcast.in
  bcast.out(0) ~> Flow[Tweet].map(_.author) ~> writeAuthors
  bcast.out(1) ~> Flow[Tweet].mapConcat(_.hashtags.toList) ~> writeHashtags
  ClosedShape
})
g.run()
```

Как вы можете видеть, внутри `GraphDSL` мы используем неявный построитель графов `b`, чтобы с легкостью построить граф, 
используя **`~>` «краевой оператор»** (также читаемый как «соеденить» или «вместе» или «к»). Оператор предоставляется 
неявно, импортируясь из `GraphDSL.Implicits._`.

`GraphDSL.create` возвращает граф, в этом примере `Graph [ClosedShape, NotUsed]`, где `ClosedShape` означает, что это 
полностью связный граф или " замкнутый” - нет неподключенных входов или выходов. Поскольку он закрыт, можно преобразовать 
граф в `RunnableGraph` с помощью `RunnableGraph.fromGraph`. Затем `RunnableGraph` можно `run()`, чтобы материализовать 
поток из него.

Оба: `Graph` и `RunnableGraph` являются неизменяемыми, потокобезопасными и свободно распространяемыми.

Граф также может иметь одну из нескольких других форм с одним или несколькими несвязанными портами. Наличие несвязанных 
портов выражает граф, который является частичным графом (`partial graph`). Понятия вокруг составления графов и вложенности в больших 
структурах подробно объясняются в [модульности, композиции и иерархии](https://doc.akka.io/docs/akka/current/stream/stream-composition.html). 
Также возможно обернуть сложные графические вычисления как потоки, стоки или источники, которые будут подробно объяснены в
 разделе [Построение источников, стоков и потоков из частичных графов](https://doc.akka.io/docs/akka/current/stream/stream-graphs.html#constructing-sources-sinks-flows-from-partial-graphs).

### Обратное давление в действии
Одним из основных преимуществ потоков Akka является то, что они всегда распространяют информацию о противодавлении от 
потоков Sinks (Подписчиков) до их источников (Издателей). Он не является дополнительной функцией и включен всегда. 

Типичными проблемными приложениями (_не использующими потоки Akka_), как это часто бывает, является то, что они не могут 
обрабатывать входящие данные достаточно быстро, и начнут буферизацию входящих данных, пока не 
будет больше места для буферизации, в результате чего - `OutOfMemoryError` или другие серьезные ухудшения оперативности 
обслуживания. С буферизацией Akka Stream можно и нужно обрабатывать явно. Например, если нас интересуют только «последние 
твиты с буфером из 10 элементов», это можно выразить с помощью элемента `buffer`:

```scala
tweets
  .buffer(10, OverflowStrategy.dropHead)
  .map(slowComputation)
  .runWith(Sink.ignore)
```
Элемент `buffer` принимает явную и требуемую `OverflowStrategy`, которая определяет, как буфер должен реагировать, когда он 
получает другой элемент, когда он заполнен. Предоставляемые стратегии включают в себя удаление самого старого элемента 
(`dropHead`), удаление всего буфера, ошибки и т.д. 

### Материализованные значения
До сих пор мы обрабатывали данные только с использованием потоков и потребляли их в какой-то внешний `Sink` - будь то 
путем печати значений или их хранения в какой-либо внешней системе. Однако иногда нам может быть интересно какое-то 
значение, которое может быть получено из материализованного конвейера обработки. Например, **мы хотим знать, 
сколько твитов мы обработали**. Хотя этот вопрос не так очевиден, чтобы дать ответ в случае бесконечного потока твитов 
(одним из способов ответа на этот вопрос в потоковой настройке было бы создание потока подсчетов, описанных как «до 
сих пор, мы обработали N твитов "), но в целом можно иметь дело с конечными потоками и придумать хороший результат, 
такой как общее количество элементов.

Во-первых, давайте напишем такой счетчик элементов, используя `Sink.fold`, и посмотрим, как выглядят типы:

```scala
val count: Flow[Tweet, Int, NotUsed] = Flow[Tweet].map(_ ⇒ 1)

val sumSink: Sink[Int, Future[Int]] = Sink.fold[Int, Int](0)(_ + _)

val counterGraph: RunnableGraph[Future[Int]] =
  tweets
    .via(count)
    .toMat(sumSink)(Keep.right)

val sum: Future[Int] = counterGraph.run()

sum.foreach(c ⇒ println(s"Всего обработано твитов: $c"))
```

Сначала мы создаем многоразовый поток, который изменяет каждый входящий твит в целое число `1`. Мы будем использовать это, 
чтобы объединить их с `Sink.fold`, которые будут суммировать все `Int` элементы  потока и сделать его результат доступным
 как `Future [Int]`. Затем мы подключаем поток твитов для подсчета с помощью `via`. Наконец, мы подключаем `Flow` к 
 предварительно подготовленному `Sink`, используя `toMat`.

Помните те таинственные параметры типа `Mat` на `Source[+ Out, + Mat]`, `Flow[-In, + Out, + Mat]` и `Sink[-In, + Mat]`? 
Они представляют собой тип значений, возвращаемых этими деталями обработки при материализации. Когда вы соединяете их 
вместе, вы можете явно комбинировать свои материализованные значения. В нашем примере мы использовали предопределенную 
функцию `Keep.right`, которая сообщает реализации только о материализованном типе оператора, добавленного в настоящее 
время вправо. Материализованным типом sumSink является `Future[Int]`, и из-за использования `Keep.right`, полученный 
`RunnableGraph` также имеет параметр типа `Future[Int]`.

Этот шаг еще не материализует конвейер обработки, он просто подготавливает описание потока, который теперь подключен к 
`Sink`, и поэтому может быть `run()`, как указано по типу: `RunnableGraph[Future [Int]]`. Затем мы вызываем `run()`, 
который использует неявный `ActorMaterializer` для материализации и запуска потока. Значение, возвращаемое вызовом 
`run()` в `RunnableGraph[T]`, имеет тип `T`. В нашем случае этот тип - `Future[Int]`, который, когда он будет завершен, 
будет содержать общую длину нашего потока твитов. В случае сбоя потока это будущее завершится сбоем.

RunnableGraph может быть повторно использован и материализован несколько раз, потому что это только «проект» потока. 
Это означает, что если мы материализируем поток, например тот, который потребляет живой поток твитов в течение минуты, 
материализованные значения для этих двух материализаций будут разными, как показано на этом примере:

```scala
val sumSink = Sink.fold[Int, Int](0)(_ + _)
val counterRunnableGraph: RunnableGraph[Future[Int]] =
  tweetsInMinuteFromNow
    .filter(_.hashtags contains akkaTag)
    .map(t ⇒ 1)
    .toMat(sumSink)(Keep.right)

// материализовать поток один раз 
val morningTweetsCount: Future[Int] = counterRunnableGraph.run()
// и потом, повторно используя поток
val eveningTweetsCount: Future[Int] = counterRunnableGraph.run()
```

Многие элементы в потоках Akka обеспечивают материализованные значения, которые могут быть использованы для получения 
либо результатов вычисления, либо управления этими элементами, которые будут подробно обсуждаться в 
`Stream Materialization`. Подводя итог этому разделу, теперь мы знаем, что происходит за кулисами, когда мы запускаем 
этот однострочный вкладыш, что эквивалентно многострочной версии выше:

```scala
val sum: Future[Int] = tweets.map(t ⇒ 1).runWith(sumSink)
```

`runWith()` - метод удобства, который автоматически игнорирует материализованное значение любых других операторов, 
кроме тех, которые были добавлены самим `runWith()`. В приведенном выше примере это означает использование `Keep.right` в 
качестве объединителя для материализованных значений.

[<= содержание](https://github.com/steklopod/Akka-Streams/blob/master/readme.md)

_Если этот проект окажется полезным тебе - нажми на кнопочку **`★`** в правом верхнем углу._

